{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hourly-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "announced-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "sys.path.insert(0, cwd + \"/..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excessive-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-robin",
   "metadata": {},
   "source": [
    "# Loads a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elder-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from koala.utils import convert_to_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polished-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/home/rodri/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "NAME_DATASET = \"ag_news\"\n",
    "def change_label(sample, dict_names):\n",
    "    sample.label = dict_names[sample.label]\n",
    "    return sample\n",
    "\n",
    "if NAME_DATASET == \"ag_news\":\n",
    "    dict_names_labels = {0: \"world\",\n",
    "                        1: \"sports\",\n",
    "                        2: \"business\",\n",
    "                        3: \"science/tech\"}\n",
    "    \n",
    "    datasets = load_dataset('ag_news')\n",
    "    dataset_train = datasets[\"train\"]\n",
    "    dataset_test = datasets[\"test\"]\n",
    "    train_samples = convert_to_samples(dataset_train)\n",
    "    test_samples = convert_to_samples(dataset_test)\n",
    "    train_samples = [change_label(s, dict_names_labels) for s in train_samples]\n",
    "    test_samples = [change_label(s, dict_names_labels) for s in test_samples]\n",
    "elif NAME_DATASET == \"per_sent\":\n",
    "    dict_names_labels = {0: \"negative\",\n",
    "                        1: \"neutral\",\n",
    "                        2: \"positive\"}\n",
    "    \n",
    "    datasets = load_dataset(\"per_sent\")\n",
    "    # We echange test and train because test is not balanced and it's too small to be balanced\n",
    "    dataset_train = datasets[\"test_random\"]\n",
    "    dataset_test = datasets[\"train\"]\n",
    "    \n",
    "    train_samples = convert_to_samples(dataset_train, 'DOCUMENT', 'TRUE_SENTIMENT')\n",
    "    test_samples = convert_to_samples(dataset_test,  'DOCUMENT', 'TRUE_SENTIMENT')\n",
    "    train_samples = [change_label(s, dict_names_labels) for s in train_samples]\n",
    "    test_samples = [change_label(s, dict_names_labels) for s in test_samples]\n",
    "    test_samples = balance_data(test_samples)\n",
    "elif NAME_DATASET == \"hate_speech_offensive\":\n",
    "    dict_names_labels = {0: \"hate_speech\",\n",
    "                    1: \"offensive\",\n",
    "                    2: \"neither\"}\n",
    "    \n",
    "    datasets = load_dataset(\"hate_speech_offensive\")\n",
    "    dataset_train = datasets[\"train\"].filter(lambda example, indice: indice < 1000, with_indices=True)\n",
    "    dataset_test = datasets[\"train\"].filter(lambda example, indice: 1000< indice, with_indices=True)\n",
    "    \n",
    "    train_samples = convert_to_samples(dataset_train, 'tweet', 'class')\n",
    "    test_samples = convert_to_samples(dataset_test,  'tweet', 'class')\n",
    "    train_samples = [change_label(s, dict_names_labels) for s in train_samples]\n",
    "    \n",
    "    test_samples = [change_label(s, dict_names_labels) for s in test_samples]\n",
    "    test_samples = balance_data(test_samples)\n",
    "elif NAME_DATASET == \"yahoo_answers_topics\":\n",
    "    datasets = load_dataset(\"yahoo_answers_topics\")\n",
    "    dataset_train = datasets[\"train\"].filter(lambda example, indice: indice < 1000, with_indices=True)\n",
    "    dataset_test = datasets[\"test\"].filter(lambda example, indice: indice < 2000, with_indices=True)\n",
    "    train_samples = convert_to_samples(dataset_train, \"question_title\", \"topic\")\n",
    "    test_samples = convert_to_samples(dataset_test,\"question_title\", \"topic\")\n",
    "    test_samples = balance_data(test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "executive-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"sports\", \"business\"]\n",
    "train_samples = [s for s in train_samples if s.label in [\"sports\", \"business\"]]\n",
    "test_samples = [s for s in test_samples if s.label in [\"sports\", \"business\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "brazilian-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_small =train_samples[:200]\n",
    "np.random.shuffle(train_samples_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "equal-works",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 3800)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "optical-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "indirect-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform([s.text for s in train_samples_small])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "hairy-occupation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1000)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "tired-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [labels.index(s.label) for s in train_samples_small]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "stone-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([101,  99]))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "stretch-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "omp = OrthogonalMatchingPursuit(n_nonzero_coefs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "exciting-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:391: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n"
     ]
    }
   ],
   "source": [
    "omp = omp.fit(X.toarray(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "advanced-homeless",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = omp.coef_\n",
    "len(coef.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "lovely-arthritis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sports', 'business']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bright-worthy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('17', 0.1657167681779543),\n",
       " ('200', -0.2864468429227494),\n",
       " ('afp', -0.1263572439590028),\n",
       " ('africa', 0.6024885380281998),\n",
       " ('amateur', -0.33273616284940427),\n",
       " ('another', -0.9807416376401726),\n",
       " ('ap', -0.009457443522249193),\n",
       " ('apple', 0.11635232232799393),\n",
       " ('arsenal', -0.4976141965793186),\n",
       " ('athens', -0.8354229899620476),\n",
       " ('athletes', 0.33556619394619225),\n",
       " ('atp', -0.0191475483340566),\n",
       " ('bacsik', -0.46435615939824515),\n",
       " ('before', 0.8416250736806827),\n",
       " ('betting', -0.5000000000000062),\n",
       " ('birdie', 0.009457443522254479),\n",
       " ('bryant', -0.3872473985844241),\n",
       " ('burn', -0.5263461103189893),\n",
       " ('canada', 0.19424711886940715),\n",
       " ('carlyle', 0.45290035397796197),\n",
       " ('chad', -0.23270464465598714),\n",
       " ('charley', -0.7991691925215543),\n",
       " ('claims', 1.7504301773016562),\n",
       " ('clear', 0.2572295856805437),\n",
       " ('clubbed', -0.39799406757696887),\n",
       " ('coach', -0.2353892787714339),\n",
       " ('colander', 0.6099150592135548),\n",
       " ('collaboration', 0.1839510791243521),\n",
       " ('companies', -0.05063926989389955),\n",
       " ('company', 5.115173514612889e-16),\n",
       " ('compete', 0.0064993315731691524),\n",
       " ('complete', 0.6651288503834791),\n",
       " ('cruised', 0.09001490672332522),\n",
       " ('defending', -0.307791225402918),\n",
       " ('diamondbacks', -0.1313310855362729),\n",
       " ('dodgers', -0.49797364278921447),\n",
       " ('due', -0.20659031578665293),\n",
       " ('earned', 0.34792306793242717),\n",
       " ('eighth', -0.05674493505954975),\n",
       " ('executives', 0.20659031578665138),\n",
       " ('family', -0.36254136167939766),\n",
       " ('following', 0.5860662790435632),\n",
       " ('fontenot', -0.4999999999999997),\n",
       " ('fourth', -1.1539073496839025),\n",
       " ('francisco', -0.3079438736158094),\n",
       " ('french', -1.7693450643461839),\n",
       " ('grim', 0.4086514709332746),\n",
       " ('hamilton', 0.014804010681720168),\n",
       " ('hellip', -0.2327046446559879),\n",
       " ('helps', -0.9308185786239547),\n",
       " ('highest', -0.46087842590426553),\n",
       " ('how', -0.20659031578664636),\n",
       " ('huey', -0.1812706808396968),\n",
       " ('hungarian', -0.7930331395217797),\n",
       " ('injury', 0.16343884271898915),\n",
       " ('innings', -0.8078712649826163),\n",
       " ('iran', 0.1442055363457326),\n",
       " ('iraq', 0.5344200237505288),\n",
       " ('jay', 0.10121512904592177),\n",
       " ('jones', -0.15679742986578873),\n",
       " ('knows', -0.9999999999999988),\n",
       " ('leonard', -0.37528862918133044),\n",
       " ('loaiza', 0.23480058762971634),\n",
       " ('making', 0.07494092968424829),\n",
       " ('mark', 0.7021676694794714),\n",
       " ('marlins', 0.1123901098020386),\n",
       " ('medals', -0.605738203814783),\n",
       " ('minutes', -1.603628296168197),\n",
       " ('miresmaeili', -0.32412766150683714),\n",
       " ('miss', -0.18439528191424334),\n",
       " ('months', 0.4801322904089991),\n",
       " ('night', -0.7642811479465149),\n",
       " ('nightmare', 3.000904383901266e-14),\n",
       " ('offensive', -0.30907687964304426),\n",
       " ('oil', -4.2677970966105384e-16),\n",
       " ('opponent', 0.2945338595730581),\n",
       " ('pau', -0.118092058860215),\n",
       " ('pay', 0.46540928931197595),\n",
       " ('penalty', -0.025555089927984897),\n",
       " ('pipeline', -0.3902144874047986),\n",
       " ('player', -0.6374586383206061),\n",
       " ('players', -0.27491727664120447),\n",
       " ('practice', -0.5263461103189895),\n",
       " ('pre', 0.17618743196434283),\n",
       " ('presidential', -1.069042876171668),\n",
       " ('proves', 0.5031160718564728),\n",
       " ('race', -0.2069668604782242),\n",
       " ('ranked', -0.4121721888765751),\n",
       " ('renault', 0.23580757302885955),\n",
       " ('report', 0.018914887044524507),\n",
       " ('return', -0.9999999999999951),\n",
       " ('rivals', 0.0428324258507015),\n",
       " ('rookie', -0.8156047180857533),\n",
       " ('run', -0.46960117525944034),\n",
       " ('said', -0.07160710768247484),\n",
       " ('saturday', -0.2168039650089833),\n",
       " ('set', -0.41771149498102056),\n",
       " ('several', -0.7966898310412647),\n",
       " ('singles', -1.0143971239698657),\n",
       " ('starts', -0.12397990184148909),\n",
       " ('straits', -0.5639137213375676),\n",
       " ('sunday', 0.07160710768247777),\n",
       " ('suspended', -0.014804010681717503),\n",
       " ('tax', -0.0506075645229587),\n",
       " ('team', -0.23618411772043216),\n",
       " ('teams', -0.3679021582487042),\n",
       " ('tech', -0.4086514709332705),\n",
       " ('thursday', -0.07519477345098387),\n",
       " ('tiger', 0.06854571424168392),\n",
       " ('track', -0.8354890206809015),\n",
       " ('under', -0.9202874634743848),\n",
       " ('upsets', -0.7638158822795628),\n",
       " ('usc', -0.8760200981585103),\n",
       " ('virginia', 0.4608784259042758),\n",
       " ('visiting', 0.2046297787259141),\n",
       " ('wake', 1.05012798912714),\n",
       " ('win', -0.13240475716358965),\n",
       " ('wis', -1.1012151290459173),\n",
       " ('yesterday', 0.10121512904591805)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = vectorizer.get_feature_names()\n",
    "[(word_index[i], coef[i]) for i in coef.nonzero()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "instrumental-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform([s.text for s in test_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "medieval-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [labels.index(s.label) for s in test_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "greenhouse-justice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([1900, 1900]))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "exotic-teddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800, 1000)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "interested-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test = X_test * np.transpose(coef)\n",
    "y_predicted_test = [0 if x < 0.5 else 1 for x in y_predicted_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "burning-resort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.96      0.66      1900\n",
      "           1       0.63      0.07      0.12      1900\n",
      "\n",
      "    accuracy                           0.51      3800\n",
      "   macro avg       0.57      0.51      0.39      3800\n",
      "weighted avg       0.57      0.51      0.39      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(list(y_test), list(y_predicted_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "colonial-teens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.513421052631579"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-excellence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FewSampleClassifier",
   "language": "python",
   "name": "fewsampleclassifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
