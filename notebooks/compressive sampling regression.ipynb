{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "governing-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "endless-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lyric-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def lemmatizer(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([t.lemma_ for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-birmingham",
   "metadata": {},
   "source": [
    "# Carga de datos\n",
    "Vamos a descargar un dataset de regresión sobre texto.\n",
    "\n",
    "Datasets info: https://huggingface.co/datasets/app_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "harmful-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset app_reviews (/home/rodri/.cache/huggingface/datasets/app_reviews/default/0.0.0/af305ac963fd8dff5976dd341e97edf3a2933c3509a58885caace361c5cd3fe3)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"app_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electoral-appraisal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['package_name', 'review', 'date', 'star'],\n",
       "    num_rows: 288065\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conscious-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('com.google.android.gms', 103535),\n",
       " ('org.telegram.messenger', 22816),\n",
       " ('org.ppsspp.ppsspp', 9771),\n",
       " ('com.frostwire.android', 8867),\n",
       " ('com.google.android.marvin.talkback', 7807),\n",
       " ('org.wikipedia', 5410),\n",
       " ('net.sourceforge.opencamera', 3992),\n",
       " ('org.wordpress.android', 3200),\n",
       " ('com.google.android.apps.authenticator2', 2976),\n",
       " ('org.torproject.android', 2941)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(*np.unique(dataset[\"train\"][\"package_name\"], return_counts=True)), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-trainer",
   "metadata": {},
   "source": [
    "**Package name**: identificador de la aplicación\n",
    "\n",
    "**Review**: texto con la opinión de la app\n",
    "\n",
    "**Date**: Fecha de la review\n",
    "\n",
    "**Star**: puntuación de 1 a 5 estrellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "usual-immune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECTED PACKAGE:  org.telegram.messenger\n"
     ]
    }
   ],
   "source": [
    "package = 'org.telegram.messenger'\n",
    "print(\"SELECTED PACKAGE: \", package)\n",
    "texts_of_package = [i for i, x in enumerate(dataset[\"train\"][\"package_name\"]) if x == package]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "powered-ebony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  22816\n"
     ]
    }
   ],
   "source": [
    "texts = np.asarray(dataset['train']['review'])[texts_of_package]\n",
    "targets = np.asarray(dataset['train']['star'])[texts_of_package]\n",
    "print(\"Number of samples: \", len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opening-passage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(targets)\n",
    "plt.title(\"Histogram for targets\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "silver-canadian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome app\n",
      "5 stars\n",
      "=======================\n",
      "Nice\n",
      "1 stars\n",
      "=======================\n",
      "Rkj Fine\n",
      "5 stars\n",
      "=======================\n",
      "My Telegram I Love It\n",
      "5 stars\n",
      "=======================\n",
      "Its good application i love it.....\n",
      "5 stars\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(texts[i])\n",
    "    print(f\"{targets[i]} stars\")\n",
    "    print(\"=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-forward",
   "metadata": {},
   "source": [
    "Vamos a simular no tener la gran cantidad de datos que tenemos. Para ello vamos a tomar solo una pequeña parte de las muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "informational-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_train = 2_000\n",
    "n_samples_test = 1_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-armstrong",
   "metadata": {},
   "source": [
    "Separamos en training y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "violent-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "texts_train, texts_test, y_train, y_test = train_test_split(texts, targets, train_size=n_samples_train, test_size=n_samples_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "narrow-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts_train = list(map(lemmatizer, texts_train))\n",
    "# texts_test = list(map(lemmatizer, texts_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-colon",
   "metadata": {},
   "source": [
    "# Generación de features\n",
    "Vamos a usar un CountVectorizer. Se generarán N features, una por cada palabra que aparezca en el dataset. Cada texto será codificado un vector de N posiciones, donde cada posición representa el número de veces que contiene la palabra correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "floppy-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords = [\"best\", \"bad\", \"love\", \"hate\", \"great\", \"good\", \"thanks\", \"not\", \"awesome\"]\n",
    "stopwords = []\n",
    "cv = CountVectorizer(\n",
    "    ngram_range=(1, 3), # Se generan n-gramas de hasta 3 tokens\n",
    "    min_df=2, # Solo se tomarán las palabras que aparezcan al menos un número mínimo de veces\n",
    "    stop_words=stopwords\n",
    ")\n",
    "X_train = cv.fit_transform(texts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "respective-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algunas de las features generadas:  ['but there', 'and the best', 'the new', 'the problem is', 'status', 'add features', 'made in', 'good its', 'min', 'it but']\n"
     ]
    }
   ],
   "source": [
    "print(\"Algunas de las features generadas: \", random.sample(cv.get_feature_names(), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "adjusted-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cv.transform(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "preceding-marks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAMAÑO DEL DATASET DE ENTRANAMIENTO:  (2000, 3338)\n"
     ]
    }
   ],
   "source": [
    "print(\"TAMAÑO DEL DATASET DE ENTRANAMIENTO: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-company",
   "metadata": {},
   "source": [
    "Vamos a escalar las features para que tengan la misma norma.\n",
    "\n",
    "En lugar de escalarlo a norma 1, vamos a hacerlo de forma que todos tengan la norma de la feauture con mayor norma. Esto evita algunos problemas de redondeos a cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "located-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = X_train.toarray()\n",
    "X_test_norm = X_test.toarray()\n",
    "higher_norm = max([np.linalg.norm(X_train_norm[:, i]) for i in range(X_train.shape[1])])\n",
    "       \n",
    "for i in range(X_train.shape[1]):\n",
    "    coeff = higher_norm / np.linalg.norm(X_train_norm[:, i])\n",
    "    X_train_norm[:, i] = X_train_norm[:, i] * coeff\n",
    "    X_test_norm[:, i] = X_test_norm[:, i] * coeff\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-essay",
   "metadata": {},
   "source": [
    "# Modelo baseline: Linear Regressor\n",
    "Entrenamos un regresor lineal simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dedicated-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "painful-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "interim-species",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.23343088340881468\n",
      "Test score:  4.288439983188699\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score: \", mean_squared_error(y_train, lr.predict(X_train)))\n",
    "print(\"Test score: \", mean_squared_error(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "opening-ordinance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST IMPORTANT 20 words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('thanks for this', 5.018114068121205),\n",
       " ('just awesome', 4.395789983814475),\n",
       " ('awesome thanks', -4.174124723052002),\n",
       " ('in india', -4.153721334990498),\n",
       " ('can not', -4.138257618172726),\n",
       " ('plz', -3.9999784425193976),\n",
       " ('nature', 3.9908777501692705),\n",
       " ('thanx', -3.742483269995731),\n",
       " ('app great', -3.7302621724770755),\n",
       " ('messaging', -3.622894801484117),\n",
       " ('emoji', -3.555705525979014),\n",
       " ('love this', 3.4557464412770895),\n",
       " ('like that', 3.452252300760432),\n",
       " ('share', 3.251390926841963),\n",
       " ('this application', -3.217071306059347),\n",
       " ('messaging app', 3.2009921796492184),\n",
       " ('that good', 3.1769481342644212),\n",
       " ('love this app', -3.142254006282895),\n",
       " ('not safe', -3.071337703831804),\n",
       " ('adds', 2.8384431178940353)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_important_words = 20\n",
    "print(\"MOST IMPORTANT {} words\".format(n_important_words))\n",
    "sorted(list(list(zip(cv.get_feature_names(), lr.coef_))), key=lambda x: abs(x[1]), reverse=True)[:n_important_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-riding",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "secure-furniture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4354939221393579, tolerance: 0.18982993749999996\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.357994019663181, tolerance: 0.18982993749999996\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0508250557468273, tolerance: 0.18982993749999996\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.876377941016983, tolerance: 0.18982993749999996\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24140915026333687, tolerance: 0.1939177500000001\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8218572045307724, tolerance: 0.1939177500000001\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0609273833665043, tolerance: 0.1939177500000001\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.293453090854655, tolerance: 0.1939177500000001\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0577029313183743, tolerance: 0.19783099999999984\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8332680671772437, tolerance: 0.19783099999999984\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.795728283020651, tolerance: 0.19783099999999984\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4617428378639374, tolerance: 0.19866775000000025\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.127821509103569, tolerance: 0.19866775000000025\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.141291131251876, tolerance: 0.19866775000000025\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4427993386546518, tolerance: 0.2042984375\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8427688256497845, tolerance: 0.2042984375\n",
      "  positive)\n",
      "/home/rodri/PycharmProjects/ClasificacionSinMuestras/venv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.422688968301543, tolerance: 0.2042984375\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso_model = LassoCV(n_alphas=10).fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "egyptian-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.5298888228395948\n",
      "Test score:  0.2166252799294175\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score: \", r2_score(y_train, lasso_model.predict(X_train_norm)))\n",
    "print(\"Test score: \", r2_score(y_test, lasso_model.predict(X_test_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "collaborative-danger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([c for c in lasso_model.coef_ if c != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-positive",
   "metadata": {},
   "source": [
    "# OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "numerous-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import OrthogonalMatchingPursuit,  OrthogonalMatchingPursuitCV\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "alpine-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "omp =  OrthogonalMatchingPursuitCV(max_iter=50)\n",
    "omp = omp.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "another-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gcv = GridSearchCV(omp, param_grid={\"n_nonzero_coefs\": range(50, 200, 20)}, scoring=\"r2\").fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "artificial-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv = omp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "unlimited-sunrise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.n_nonzero_coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "rural-switch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.16044807136304295\n",
      "Test score:  0.1197781876010513\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score: \", r2_score(y_train, gcv.predict(X_train_norm)))\n",
    "print(\"Test score: \", r2_score(y_test, gcv.predict(X_test_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dressed-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', -0.38891198364213503),\n",
       " ('hate', -0.28465963730773114),\n",
       " ('religion', -0.2332330876632032),\n",
       " ('doesn', -0.23125299686186407),\n",
       " ('dont', -0.22753808831982078),\n",
       " ('trying', -0.2106107843028904)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_null_indices = [i for i,x in enumerate(gcv.coef_) if x != 0]\n",
    "\n",
    "    \n",
    "sorted(list(filter(lambda x: x[1] != 0, list(zip(cv.get_feature_names(), gcv.coef_)))), key=lambda x: abs(x[1]), reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "micro-banks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I hate this app This application include some stickers (modern budha) and it's insulting our religion. And it shouldn't be there. So please  telegrame developers remove that sticker pack.\",\n",
       " 'Disappointed such a shame that an app with millions of users made a dumb move like insulting a religion. buddhist people are using this app too. so... good luck with pissing users off.',\n",
       " \"Urgently remove the modern buddha stickers pack!!Are u making fun of religion???? 😶 Remove the 'modern buddha' stickers in ur stickers pack. It's insulting to Buddhism!!! 👎👎👎 👎👎👎👎👎\",\n",
       " 'Racist මේ app එක install කරන්න එපා. බුදුහාමුදුරුවන්ට නින්දා වෙන විදිහෙ sticker වගයක් තියනව.. There is sticker set named modern Buddha. Dont install this app. Stop making fun from any religion. Plz dont install this app.',\n",
       " \"Please remove Lord Buddha Sticker Please reove Lord Buddha stickers from your app. It's a insulting for a religion and don't do this for any religion.\",\n",
       " \"Shoutout to all the telegram haters I can't believe people could be so sensitive to a sticker pack that telegram made. If you guys are so deeply religious  this would not even bother you in the first place. It's a joke to see bad reviews base on this  there is nothing wrong with the sticker packs. It might be unusual and out of the ordinary  but it's totally fine and it does not insult the religion in any way.\",\n",
       " \"Insalt religions in this app Don't download it I hope This app create person Burn to die\",\n",
       " \"Umesh U don't have any right to insults any religion. You are insulting Load Buddha our religious leader. Not only that u are insulting Pope also. How gave you thr right to insult any religion? Are u that much ass hole?\",\n",
       " 'Very bad.they are making fun of religion',\n",
       " 'Bad I hate this app.bacause this app owner is used lord budhdhas pictures..dont use use this up anyone.its not good for budhdhist religion ever..',\n",
       " 'Remove MODERN BUDDHA Sticker Please remove modern Buddha strikers from stickers in this app. Please respect religions.',\n",
       " \"What is modern buddha... don't humiliate other religions... we very very respect to him.. but in this application humiliated to lord buddha...\",\n",
       " \"Not cool Buddha's teaching is the kindest religion on earth which could never harm or insult to anyone .so please remove those stickers called Modern Buddha which are insulting the teacher of our religion lord BUDDHA.\",\n",
       " \"I Removed it Don't make fun out of religions\",\n",
       " \"Hate it Remove modern buddha sticker pack. What is the problem with you our religion guy's?\",\n",
       " \"F*ck Remove the modern buddha stiker Don't dishonour to other religions Remove it\",\n",
       " 'There are lord buddha stickers.Are you getting fun from this? Buddhism is a religion and please remove it soon.',\n",
       " 'Bull යාළුවෙන් මේ අැප් එකේ අපේ බුදු හාමුදුරුවන්ට නින්දා වන විදියේ ස්ටිකර් වගයක් තියනවා. මේ අැප් එක රිපෝර්ට් කරන්න. Install කරන්න එපා.. I hate this. There is a Sticker set name Modern Buddha. Is our religion is trouble to you. Please romove it. I unstall this app.',\n",
       " 'This is Disrespect to our buddhist religion We All Report This App',\n",
       " 'Remove the modern buddha sticker pack Dont insult to other religions',\n",
       " 'Upset Pls remove sticker called modern buddah. That insult our religion.',\n",
       " \"please remove 'modern buddha' sticker set don't get a religion as a joke\",\n",
       " 'Remove \"\"\"\"\"\"\"\"Modern Buddha\"\"\"\"\"\"\"\" stiker pack The stiker pack is insulting our religion. Many of sri lankan people are alredy removed your app for that remove the stiker pack.\"\"',\n",
       " 'What a looser app This app inclueds our buddhas sticker pack we tell you for that very angry pls remove that sticker pack thats oure religious like a christian religions we are buddhist',\n",
       " \"Hate this...... It's a shame that Insulting & making fun with religions.uninstalled.buddists and christians report this.\",\n",
       " 'Please remove \"\"\"\"\"\"\"\"Modern Buddha\"\"\"\"\"\"\"\" sticker. Developers please remove the stickers called \"\"\"\"\"\"\"\"Modern Buddha\"\"\"\"\"\"\"\". Buddhism is our religion. So u take it down fast. Buddhism isnt\\' a joke. Please remove it.\"\"',\n",
       " 'Very bad. They are making fun of religions! You released a sticker pack called \"\"\"\"\"\"\"\"Modern Buddha\"\"\"\"\"\"\"\" and that\\'s not a good way to promote the app! And already me and my friends removed the app from every device we have the app installed. Never gonna use again!\"\"',\n",
       " \"This telegram app mekers are cheaters and gutless people. I think they are profane or none religions. Because a religion used theirs population. What is your problem with buddhism. You Can Insult BUDDHISM. But you can't destroy buddhism. We can abuse this rude people. But We Commiserate Them. May the triple geme bless you\",\n",
       " \"Urgently remove the modern buddha stickers pack!!???? 😶 @telegram there's a stickers pack which called 'modern buddha ' is insulating to our religion and pls remove that stickers urgently!!!👎👎 👎👎👎👎👎👎\",\n",
       " \"Talking about modern Buddha ...its so offensive Well...it might be hilarious for some people....... Especially who have no respect to any religion at all...but come on man its not cool to insult a religion like that that's being respected by the all the Buddhists worldwide... Just think if we made up a modern all mighty Allah or a Jesus............I have no idea what the hell were u guys thinking to bring up a concept like this..👎👎\",\n",
       " 'I hated it. I hate this app. Because there is a sticker pack named \"\"\"\"\"\"\"\"Modern Buddha\"\"\"\"\"\"\"\" It\\'s insulting our religion. Please be kind enough to pay attention and remove it.\"\"',\n",
       " \"Pls be mindful when you are adding stickers Pls be kind enough to remove our lord Buddha's stickers. I'm going to uninstall this app now. I saw some of guys have written that mentioned to ask Buddha to send a request to remove it. Pls don't show your stupidity to others mentioning those shame words. Be more careful when you create something related to any religion. As a human being respect to each others religion.\",\n",
       " \"Inappropriate Stickers If you have a problem with other religions please don't try to spread your sickness to others. Please remove those inappropriate stickers!\",\n",
       " 'Hate this Why does you insulting a religion or a religious leader.it must to be stopped.dont insult buddhisum.',\n",
       " \"Umesh U don't have any right to insults any religion. You are insulting Load Buddha our religious leader. Not only that u are insulting Pope also. Who gave you thr right to insult any religion? Are u that much ass hole?\",\n",
       " \"You don't mess with my religion\",\n",
       " \"We disappointed. Please remove Load BUDHDHAH stickers. Why are you doing like this. Don't joke with our religion.\",\n",
       " 'Devoloper is a Racist There are emojis containing lord buddhas pictures... how can these people be such to insult any other religion. RACIST DEVOLOPER !!',\n",
       " 'Best! Just add call and it will be perfect. Ignore hindy whining about budha stickers  fu**ing religion fanatics and subhumans i piss on your budha crap 💩💩💩💩',\n",
       " 'Hate it There is stickers called modern buddha.lord buddha is our religious leader.you have no right to insult our religion so remove that stickers.',\n",
       " 'Harming for religions Hate this',\n",
       " 'Stop insulting lord buddha Stop insulting others religion . How do you feel if someone start to play with your spiritual teacher .modern jesus modern alla. Stop insulting great teacher lord budda',\n",
       " \"Please remove the sticker buddha This is our religion.please don't use it as a sticker.Don't add any sticker of our religion.Why are you doing this?.As Sri Lankan buddist people we hate this.Don't do like this fool things! Sri lankawe katiya inawa nm mekata virudha wena!! Please remove this sticker buddha\",\n",
       " \"This telegram Buddha's stickrs mekers are cheaters and gutless people. I think they are profane or none religions. Because a religion used theirs population. What is your problem with buddhism. You Can Insult BUDDHISM. But you can't destroy buddhism. We can abuse this rude people. But We Commiserate Them. May the triple geme bless you\",\n",
       " \"To be honest  this is a great app... Lot of features and stuff. But the reason behind Why I hate this app is the Stickers. Why did u guys add a bunch of stickers with Lord Buddha in it... That's Disappointing. Seriously... It's a religion  have some respect..!\",\n",
       " \"don't play with a religion.. modern buddha sticker pack Remove from ur app 😡\",\n",
       " \"Urgently remove the modern buddha stickers pack!😶 @telegram there's a stickers pack which called 'modern buddha ' is insulating to our religion and pls remove that stickers urgently!!!!👎👎 👎👎👎👎👎👎\",\n",
       " 'Crap! If you respect religions in the world please dont use this.cuz the next religion that ll be disrespected from this will be your one.',\n",
       " 'Foor Stikers no genuine foor😖 Edit our religion plz dont use this',\n",
       " \"A terrible insult to lord buddha That sticker pack containing pictures of lord Buddha is the most terrible insult I have ever seen against Buddhism. Buddhists were calm and respected the right of other people to have their own religion s. But the religious extremists are now abusing that calmness. I know  the truth is a challenge against the dazzling of the myth. That's why those aggressive extremists are afraid of Buddhism. This is not a request!! This is an order!!!!! YOU MUST IMMEDIATELY REMOVE THAT STICKERS.\",\n",
       " 'Bad app.. stickers against religion',\n",
       " \"don't get a religion as a joke\",\n",
       " \"You dishonour our religion ( Buddhist) in your stickers... plz don't it...\"]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in texts if \"religion\" in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-unknown",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FewSampleClassifier",
   "language": "python",
   "name": "fewsampleclassifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
